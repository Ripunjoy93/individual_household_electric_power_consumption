{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic LSTM model using univariate data, given a sequence of global_active_power, will try to predict a sequence of global_active_power (vector output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "# !/usr/bin/env python3\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.0-rc1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dataset, if file is not available run: 1_Exploratory_Analylis.ipynb\n",
    "df = pd.read_csv(\"./data/cleaned_household_power_consumption.csv\", infer_datetime_format=True, parse_dates=[\"local_time\"],\n",
    "                index_col=[\"local_time\"], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just to be safer, data is already sorted\n",
    "df.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>global_active_power</th>\n",
       "      <th>global_reactive_power</th>\n",
       "      <th>voltage</th>\n",
       "      <th>global_intensity</th>\n",
       "      <th>sub_metering_1</th>\n",
       "      <th>sub_metering_2</th>\n",
       "      <th>sub_metering_3</th>\n",
       "      <th>sub_metering_other</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>local_time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:24:00</th>\n",
       "      <td>4.216</td>\n",
       "      <td>0.418</td>\n",
       "      <td>234.839996</td>\n",
       "      <td>18.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>52.266670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:25:00</th>\n",
       "      <td>5.360</td>\n",
       "      <td>0.436</td>\n",
       "      <td>233.630005</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>72.333336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:26:00</th>\n",
       "      <td>5.374</td>\n",
       "      <td>0.498</td>\n",
       "      <td>233.289993</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>70.566666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:27:00</th>\n",
       "      <td>5.388</td>\n",
       "      <td>0.502</td>\n",
       "      <td>233.740005</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>71.800003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:28:00</th>\n",
       "      <td>3.666</td>\n",
       "      <td>0.528</td>\n",
       "      <td>235.679993</td>\n",
       "      <td>15.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>43.099998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     global_active_power  global_reactive_power     voltage  \\\n",
       "local_time                                                                    \n",
       "2006-12-16 17:24:00                4.216                  0.418  234.839996   \n",
       "2006-12-16 17:25:00                5.360                  0.436  233.630005   \n",
       "2006-12-16 17:26:00                5.374                  0.498  233.289993   \n",
       "2006-12-16 17:27:00                5.388                  0.502  233.740005   \n",
       "2006-12-16 17:28:00                3.666                  0.528  235.679993   \n",
       "\n",
       "                     global_intensity  sub_metering_1  sub_metering_2  \\\n",
       "local_time                                                              \n",
       "2006-12-16 17:24:00              18.4             0.0             1.0   \n",
       "2006-12-16 17:25:00              23.0             0.0             1.0   \n",
       "2006-12-16 17:26:00              23.0             0.0             2.0   \n",
       "2006-12-16 17:27:00              23.0             0.0             1.0   \n",
       "2006-12-16 17:28:00              15.8             0.0             1.0   \n",
       "\n",
       "                     sub_metering_3  sub_metering_other  \n",
       "local_time                                               \n",
       "2006-12-16 17:24:00            17.0           52.266670  \n",
       "2006-12-16 17:25:00            16.0           72.333336  \n",
       "2006-12-16 17:26:00            17.0           70.566666  \n",
       "2006-12-16 17:27:00            17.0           71.800003  \n",
       "2006-12-16 17:28:00            17.0           43.099998  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 2075259 entries, 2006-12-16 17:24:00 to 2010-11-26 21:02:00\n",
      "Data columns (total 8 columns):\n",
      "global_active_power      float32\n",
      "global_reactive_power    float32\n",
      "voltage                  float32\n",
      "global_intensity         float32\n",
      "sub_metering_1           float32\n",
      "sub_metering_2           float32\n",
      "sub_metering_3           float32\n",
      "sub_metering_other       float32\n",
      "dtypes: float32(8)\n",
      "memory usage: 79.2 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Range:  2006-12-16 17:24:00  to  2010-11-26 21:02:00\n"
     ]
    }
   ],
   "source": [
    "print(\"Data Range: \", df.index.min(), \" to \", df.index.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategies\n",
    "1. We will use sequence of **global_active_power** values to predict **global_active_power** itself. It's an univariate model.\n",
    "2. We need to provide multi-step time forecast (asking for minutely forecast for 2 days ie. 2 * 24 * 60 data points). Data start and end is not from begining minute of the first day also not till end minute of last day.\n",
    "3. For new prediction purpose, we will give give 2 days prediction. That is 2010-11-24 21:03:00 to 2010-11-24 21:02:00.\n",
    "4. Model can be trained using prior few days/minutes data (here equivalent minutes). We will start with using prior 2 days data (2880 minutes data) to train the model. It can be extended to any days, say 3, 4, 5 days. or if we look through minutes, say 3000, 4000, 5000 minutes prior.\n",
    "5. We will split the data into 3 sets (train, evaluate, test). And it will be in time series. And we will create a distict boundaries that no set can see the data from other set (be it the input sequence to train the model). We will keep last 2880 + number of data in training as train set (if we don't do this, data will overlap). Here for test data, now we have 5760 data points (considering, training with 2880 data points). We will evaluate our model with 30 days (43200 minutes), so will keep next last 32 days data (46080 minutes). And remaining data points we will use for training our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, Evaluate & Test split of univariate data:\n",
    "**(I am not creating functions now, once we are clear and confident about our steps we can wrap different building blocks as functions)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (2023419, 8)\n",
      "Evaluation data shape:  (46080, 8)\n",
      "Test data shape:  (5760, 8)\n"
     ]
    }
   ],
   "source": [
    "n_input = 2 * 24 * 60\n",
    "n_output = 2 * 24 * 60\n",
    "test_index_start = n_input + n_output\n",
    "# 30 evaluation days\n",
    "eval_days = 30\n",
    "eval_index_start = n_input + eval_days * 24 * 60 + test_index_start\n",
    "values = df.values\n",
    "train, evaluate, test = values[:-eval_index_start], values[-eval_index_start:-test_index_start], values[-test_index_start:]\n",
    "print(\"Training data shape: \", train.shape)\n",
    "print(\"Evaluation data shape: \", evaluate.shape)\n",
    "print(\"Test data shape: \", test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We are getting evaluation and test data as mentioned in our startegy**    \n",
    "Note: Still we have 8 features, we need only 1 feature (global_active_power in index 0) to build our univariate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X_y(data, n_in, n_out=2880):\n",
    "    X, y = list(), list()\n",
    "    in_start = 0\n",
    "    # step over the entire history one time step at a time\n",
    "    for _ in range(len(data)):\n",
    "        # define the end of the input sequence\n",
    "        in_end = in_start + n_input\n",
    "        out_end = in_end + n_out\n",
    "        # ensuring that we have enough data for this instance\n",
    "        if out_end <= len(data):\n",
    "            # need only 1 feature\n",
    "            x_input = data[in_start:in_end, 0]\n",
    "            # reshaping [timestemps, features]\n",
    "            x_input = x_input.reshape((len(x_input), 1))\n",
    "            # it will give [samples, timestemps, features]\n",
    "            X.append(x_input)\n",
    "            # [samples, output]\n",
    "            y.append(data[in_end:out_end, 0])\n",
    "        # move along one time step\n",
    "        in_start += 1\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, y_train = get_X_y(data=train, n_in=n_input, n_out=n_output)\n",
    "# X_eval, y_eval = get_X_y(data=evaluate, n_in=n_input, n_out=n_output)\n",
    "# X_test, y_test = get_X_y(data=test, n_in=n_input, n_out=n_output)\n",
    "# print(\"Train X shape: \", X_train.shape)\n",
    "# print(\"Train y shape: \", y_train.shape)\n",
    "# print(\"Evaluation X shape: \", X_eval.shape)\n",
    "# print(\"Evaluation y shape: \", y_eval.shape)\n",
    "# print(\"Test X shape: \", X_test.shape)\n",
    "# print(\"Test y shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Above method is taking time to generate the sets, bcause of memory issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected X_train shape: (2017660,2880,1)\n",
      "Expected X_train shape: (2017660,2880)\n"
     ]
    }
   ],
   "source": [
    "print(\"Expected X_train shape: ({},{},{})\".format(train.shape[0] - 2 * 2880 + 1, 2880, 1))\n",
    "print(\"Expected X_train shape: ({},{})\".format(train.shape[0] - 2 * 2880 + 1, 2880))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check approximately how much memory we consume by looking into first 10000 data points, the expected rows will be 10000 - 2 * 2880\n",
    "X_train, y_train = get_X_y(data=train[0:10000,:], n_in=n_input, n_out=n_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (4241, 2880, 1)  , y_train shape:  (4241, 2880)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape: \", X_train.shape, \" , y_train shape: \", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_size in MB:  46.593017578125  , y_train_size in MB:  46.593017578125\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train_size in MB: \", X_train.nbytes/(1024*1024), \" , y_train_size in MB: \", y_train.nbytes/(1024*1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected size in GB for 2017659 rows in training(X,y):  43.29428672790527  GB\n"
     ]
    }
   ],
   "source": [
    "# Lets calculate the expected size for train\n",
    "# 4241 rows need 2 * 46.58203125 mb\n",
    "print(\"Expected size in GB for 2017659 rows in training(X,y): \", \n",
    "      X_train.nbytes/(1024*1024) * 2 * (train.shape[0] - 2 * 2880 + 1)/X_train.shape[0]/1024, \" GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is why we are going out of memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can try saving these arrays to DISK and then feed to the model by fit_generator in KERAS by defining our generator. I will explore on this later.\n",
    "**For now I will move forward and try to build models by converting it to hourly records**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
